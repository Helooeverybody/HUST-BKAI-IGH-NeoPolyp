{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T05:13:47.903670Z",
     "iopub.status.busy": "2024-11-23T05:13:47.903329Z",
     "iopub.status.idle": "2024-11-23T05:14:04.119535Z",
     "shell.execute_reply": "2024-11-23T05:14:04.118676Z",
     "shell.execute_reply.started": "2024-11-23T05:13:47.903641Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchgeometry in /opt/conda/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from torchgeometry) (2.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->torchgeometry) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->torchgeometry) (1.3.0)\n",
      "Requirement already satisfied: segmentation-models-pytorch in /opt/conda/lib/python3.10/site-packages (0.3.4)\n",
      "Requirement already satisfied: efficientnet-pytorch==0.7.1 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.6 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.25.1)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (10.3.0)\n",
      "Requirement already satisfied: pretrainedmodels==0.7.4 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (1.16.0)\n",
      "Requirement already satisfied: timm==0.9.7 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.9.7)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.19.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.66.4)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.4.0)\n",
      "Requirement already satisfied: munch in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.0.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.7->segmentation-models-pytorch) (6.0.2)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.7->segmentation-models-pytorch) (0.4.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (21.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (4.12.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.26.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.1.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchgeometry\n",
    "!pip install segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T05:14:04.121676Z",
     "iopub.status.busy": "2024-11-23T05:14:04.121385Z",
     "iopub.status.idle": "2024-11-23T05:14:04.129285Z",
     "shell.execute_reply": "2024-11-23T05:14:04.128454Z",
     "shell.execute_reply.started": "2024-11-23T05:14:04.121648Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as F\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "import segmentation_models_pytorch as smp\n",
    "import wandb\n",
    "from torchgeometry.losses import DiceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T05:14:04.130548Z",
     "iopub.status.busy": "2024-11-23T05:14:04.130289Z",
     "iopub.status.idle": "2024-11-23T05:14:04.144067Z",
     "shell.execute_reply": "2024-11-23T05:14:04.143406Z",
     "shell.execute_reply.started": "2024-11-23T05:14:04.130524Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cutomize the dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T05:14:04.146724Z",
     "iopub.status.busy": "2024-11-23T05:14:04.146469Z",
     "iopub.status.idle": "2024-11-23T05:14:04.159240Z",
     "shell.execute_reply": "2024-11-23T05:14:04.158264Z",
     "shell.execute_reply.started": "2024-11-23T05:14:04.146700Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Segmentation Dataset for \n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, img_dir, label_dir, resize=None, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.resize = resize\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(self.img_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def process_mask(self, mask_path):\n",
    "        image = cv2.imread(mask_path)\n",
    "        if self.resize:\n",
    "            image = cv2.resize(image, self.resize)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        lower_red1 = np.array([0, 100, 20])\n",
    "        upper_red1 = np.array([10, 255, 255])\n",
    "        lower_red2 = np.array([160,100,20])\n",
    "        upper_red2 = np.array([179,255,255])\n",
    "        \n",
    "        lower_mask_red = cv2.inRange(image, lower_red1, upper_red1)\n",
    "        upper_mask_red = cv2.inRange(image, lower_red2, upper_red2)\n",
    "        \n",
    "        red_mask = lower_mask_red + upper_mask_red\n",
    "        red_mask[red_mask != 0] = 1\n",
    "\n",
    "        green_mask = cv2.inRange(image, (36, 25, 25), (70, 255, 255))\n",
    "        green_mask[green_mask != 0] = 2\n",
    "\n",
    "        full_mask = cv2.bitwise_or(red_mask, green_mask)\n",
    "        full_mask = np.expand_dims(full_mask, axis=-1) \n",
    "        full_mask = full_mask.astype(np.uint8)\n",
    "        return full_mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        label_path = os.path.join(self.label_dir, self.images[idx])\n",
    "        image = cv2.imread(img_path)  #  BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert to RGB\n",
    "        label = self.process_mask(label_path)  \n",
    "        image = cv2.resize(image, self.resize)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    \n",
    "# Customize dataset for training phase and inference\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.data[index]\n",
    "        label = self.targets[index]\n",
    "        assert image.shape[:2] == label.shape[:2]\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=label)\n",
    "            image = transformed['image'].float()\n",
    "            label = transformed['mask'].float()\n",
    "            label = label.permute(2, 0, 1)\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T05:14:04.160774Z",
     "iopub.status.busy": "2024-11-23T05:14:04.160454Z",
     "iopub.status.idle": "2024-11-23T05:14:04.351016Z",
     "shell.execute_reply": "2024-11-23T05:14:04.350220Z",
     "shell.execute_reply.started": "2024-11-23T05:14:04.160739Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000\n"
     ]
    }
   ],
   "source": [
    "images_path = \"/kaggle/input/bkai-igh-neopolyp/train/train/\"\n",
    "image_path = []\n",
    "mask_path = []\n",
    "TRAIN_DIR = '/kaggle/input/bkai-igh-neopolyp/train/train'\n",
    "TRAIN_MASK_DIR = '/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt'\n",
    "for root, dirs, files in os.walk(TRAIN_DIR):\n",
    "    for file in files:\n",
    "        path = os.path.join(root,file)\n",
    "        image_path.append(path)\n",
    "for root, dirs, files in os.walk(TRAIN_MASK_DIR):\n",
    "    for file in files:\n",
    "        path = os.path.join(root,file)\n",
    "        mask_path.append(path)\n",
    "print(len(image_path), len(mask_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T05:14:04.352266Z",
     "iopub.status.busy": "2024-11-23T05:14:04.352020Z",
     "iopub.status.idle": "2024-11-23T05:14:05.247618Z",
     "shell.execute_reply": "2024-11-23T05:14:05.246681Z",
     "shell.execute_reply.started": "2024-11-23T05:14:04.352242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# load pretrained model in dataset imagenet with encoder \"efficientnet-b7\"\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"efficientnet-b7\",        \n",
    "    encoder_weights=\"imagenet\",     \n",
    "    in_channels=3,                  \n",
    "    classes=3     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T05:14:05.249171Z",
     "iopub.status.busy": "2024-11-23T05:14:05.248809Z",
     "iopub.status.idle": "2024-11-23T05:14:05.258550Z",
     "shell.execute_reply": "2024-11-23T05:14:05.257653Z",
     "shell.execute_reply.started": "2024-11-23T05:14:05.249124Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# use this data augmentation\n",
    "train_transforms = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.RandomCrop(height=256, width=256, p=0.5),\n",
    "    A.GaussNoise(p=0.2),\n",
    "    A.Rotate(limit=30, p=0.3),\n",
    "    A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "val_transforms = A.Compose([\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T05:14:05.259882Z",
     "iopub.status.busy": "2024-11-23T05:14:05.259590Z",
     "iopub.status.idle": "2024-11-23T05:14:05.280165Z",
     "shell.execute_reply": "2024-11-23T05:14:05.279353Z",
     "shell.execute_reply.started": "2024-11-23T05:14:05.259858Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = SegmentationDataset(img_dir= TRAIN_DIR,\n",
    "                             label_dir= TRAIN_MASK_DIR,\n",
    "                             resize= (256,256),\n",
    "                             transform = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T05:14:05.281405Z",
     "iopub.status.busy": "2024-11-23T05:14:05.281157Z",
     "iopub.status.idle": "2024-11-23T05:14:19.177870Z",
     "shell.execute_reply": "2024-11-23T05:14:19.176917Z",
     "shell.execute_reply.started": "2024-11-23T05:14:05.281381Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "images_data = []\n",
    "labels_data = []\n",
    "for x,y in dataset:\n",
    "    images_data.append(x)\n",
    "    labels_data.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T05:14:19.180404Z",
     "iopub.status.busy": "2024-11-23T05:14:19.180116Z",
     "iopub.status.idle": "2024-11-23T05:14:19.190982Z",
     "shell.execute_reply": "2024-11-23T05:14:19.190208Z",
     "shell.execute_reply.started": "2024-11-23T05:14:19.180377Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(images_data))\n",
    "val_size = len(images_data) - train_size\n",
    "\n",
    "train_dataset = CustomDataset(images_data[:train_size], labels_data[:train_size], transform=train_transforms)\n",
    "val_dataset = CustomDataset(images_data[train_size:], labels_data[train_size:], transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T05:14:19.192108Z",
     "iopub.status.busy": "2024-11-23T05:14:19.191854Z",
     "iopub.status.idle": "2024-11-23T05:14:19.212908Z",
     "shell.execute_reply": "2024-11-23T05:14:19.212159Z",
     "shell.execute_reply.started": "2024-11-23T05:14:19.192084Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T05:14:19.214140Z",
     "iopub.status.busy": "2024-11-23T05:14:19.213881Z",
     "iopub.status.idle": "2024-11-23T05:14:19.219770Z",
     "shell.execute_reply": "2024-11-23T05:14:19.219041Z",
     "shell.execute_reply.started": "2024-11-23T05:14:19.214116Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "color_dict= {0: (0, 0, 0),\n",
    "             1: (255, 0, 0),\n",
    "             2: (0, 255, 0)}\n",
    "def mask_to_rgb(mask, color_dict):\n",
    "    output = np.zeros((mask.shape[0], mask.shape[1], 3))\n",
    "\n",
    "    for k in color_dict.keys():\n",
    "        output[mask==k] = color_dict[k]\n",
    "\n",
    "    return np.uint8(output)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T05:32:51.578722Z",
     "iopub.status.busy": "2024-11-23T05:32:51.578366Z",
     "iopub.status.idle": "2024-11-23T05:32:54.327794Z",
     "shell.execute_reply": "2024-11-23T05:32:54.326955Z",
     "shell.execute_reply.started": "2024-11-23T05:32:51.578691Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:eb6lwxhr) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff3c9718399474a88e15687418315a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.018 MB of 0.018 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train_loss</td><td>█▄▃▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_loss</td><td>█▄▃▃▂▂▁▁▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train_loss</td><td>0.03875</td></tr><tr><td>Val_loss</td><td>0.07598</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stellar-waterfall-11</strong> at: <a href='https://wandb.ai/nhatminh15102004hp-hanoi-university-of-science-and-techn/BKAI-IGH%20NeoPolyp%20Deep%20Learning/runs/eb6lwxhr' target=\"_blank\">https://wandb.ai/nhatminh15102004hp-hanoi-university-of-science-and-techn/BKAI-IGH%20NeoPolyp%20Deep%20Learning/runs/eb6lwxhr</a><br/> View project at: <a href='https://wandb.ai/nhatminh15102004hp-hanoi-university-of-science-and-techn/BKAI-IGH%20NeoPolyp%20Deep%20Learning' target=\"_blank\">https://wandb.ai/nhatminh15102004hp-hanoi-university-of-science-and-techn/BKAI-IGH%20NeoPolyp%20Deep%20Learning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241123_051419-eb6lwxhr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:eb6lwxhr). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241123_053251-rlla5dsh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nhatminh15102004hp-hanoi-university-of-science-and-techn/BKAI-IGH%20NeoPolyp%20Deep%20Learning/runs/rlla5dsh' target=\"_blank\">dauntless-wave-12</a></strong> to <a href='https://wandb.ai/nhatminh15102004hp-hanoi-university-of-science-and-techn/BKAI-IGH%20NeoPolyp%20Deep%20Learning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nhatminh15102004hp-hanoi-university-of-science-and-techn/BKAI-IGH%20NeoPolyp%20Deep%20Learning' target=\"_blank\">https://wandb.ai/nhatminh15102004hp-hanoi-university-of-science-and-techn/BKAI-IGH%20NeoPolyp%20Deep%20Learning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nhatminh15102004hp-hanoi-university-of-science-and-techn/BKAI-IGH%20NeoPolyp%20Deep%20Learning/runs/rlla5dsh' target=\"_blank\">https://wandb.ai/nhatminh15102004hp-hanoi-university-of-science-and-techn/BKAI-IGH%20NeoPolyp%20Deep%20Learning/runs/rlla5dsh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nhatminh15102004hp-hanoi-university-of-science-and-techn/BKAI-IGH%20NeoPolyp%20Deep%20Learning/runs/rlla5dsh?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7de0bf7139d0>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(\n",
    "    key = \"d0ecf10144842718b6ac6ce6f532824de05f1819\",\n",
    ")\n",
    "wandb.init(\n",
    "    project = \"BKAI-IGH NeoPolyp Deep Learning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T05:33:06.910416Z",
     "iopub.status.busy": "2024-11-23T05:33:06.910086Z",
     "iopub.status.idle": "2024-11-23T06:04:23.673251Z",
     "shell.execute_reply": "2024-11-23T06:04:23.672415Z",
     "shell.execute_reply.started": "2024-11-23T05:33:06.910392Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   0%|          | 0/30 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:2388: UserWarning: Run (eb6lwxhr) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n",
      "Total Progress:   7%|▋         | 2/30 [02:25<34:02, 72.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Train Loss: 0.0358490890 , Val Loss: 0.0809399113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   7%|▋         | 2/30 [02:06<29:19, 62.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30], Train Loss: 0.0353193205 , Val Loss: 0.0814467520\n",
      "Epoch [3/30], Train Loss: 0.0325924499 , Val Loss: 0.0725141168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  10%|█         | 3/30 [03:09<28:30, 63.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30], Train Loss: 0.0292371282 , Val Loss: 0.0707837865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  17%|█▋        | 5/30 [05:16<26:20, 63.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30], Train Loss: 0.0280334569 , Val Loss: 0.0832009763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  20%|██        | 6/30 [06:18<25:09, 62.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30], Train Loss: 0.0283856133 , Val Loss: 0.0744428709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  23%|██▎       | 7/30 [07:21<24:02, 62.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/30], Train Loss: 0.0235750458 , Val Loss: 0.0770555362\n",
      "Epoch [8/30], Train Loss: 0.0259431105 , Val Loss: 0.0688839778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  30%|███       | 9/30 [09:27<22:02, 62.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/30], Train Loss: 0.0251618787 , Val Loss: 0.0747241825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  33%|███▎      | 10/30 [10:30<20:55, 62.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30], Train Loss: 0.0254976060 , Val Loss: 0.0710566118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  37%|███▋      | 11/30 [11:32<19:50, 62.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/30], Train Loss: 0.0224656524 , Val Loss: 0.0724169165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  40%|████      | 12/30 [12:34<18:45, 62.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30], Train Loss: 0.0222639694 , Val Loss: 0.0803529695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  43%|████▎     | 13/30 [13:37<17:41, 62.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/30], Train Loss: 0.0228492685 , Val Loss: 0.0745179877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  47%|████▋     | 14/30 [14:39<16:37, 62.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/30], Train Loss: 0.0189175888 , Val Loss: 0.0749946982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  50%|█████     | 15/30 [15:41<15:34, 62.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/30], Train Loss: 0.0202480718 , Val Loss: 0.0723775923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  53%|█████▎    | 16/30 [16:44<14:33, 62.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/30], Train Loss: 0.0176379422 , Val Loss: 0.0735071376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  57%|█████▋    | 17/30 [17:46<13:30, 62.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/30], Train Loss: 0.0186472809 , Val Loss: 0.0855246633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  60%|██████    | 18/30 [18:48<12:27, 62.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30], Train Loss: 0.0192827007 , Val Loss: 0.0757475272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  63%|██████▎   | 19/30 [19:50<11:25, 62.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30], Train Loss: 0.0188828810 , Val Loss: 0.0777375400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  67%|██████▋   | 20/30 [20:53<10:23, 62.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/30], Train Loss: 0.0158890221 , Val Loss: 0.0816112682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  70%|███████   | 21/30 [21:55<09:20, 62.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/30], Train Loss: 0.0169882176 , Val Loss: 0.0813733786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  73%|███████▎  | 22/30 [22:57<08:18, 62.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/30], Train Loss: 0.0178102036 , Val Loss: 0.0730658025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  77%|███████▋  | 23/30 [24:00<07:16, 62.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/30], Train Loss: 0.0183084438 , Val Loss: 0.0811271369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  80%|████████  | 24/30 [25:02<06:13, 62.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/30], Train Loss: 0.0156751014 , Val Loss: 0.0823632404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  83%|████████▎ | 25/30 [26:04<05:11, 62.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/30], Train Loss: 0.0162881276 , Val Loss: 0.0764482319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  87%|████████▋ | 26/30 [27:07<04:09, 62.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/30], Train Loss: 0.0151248115 , Val Loss: 0.0805058628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  90%|█████████ | 27/30 [28:09<03:07, 62.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/30], Train Loss: 0.0164413851 , Val Loss: 0.0774941742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  93%|█████████▎| 28/30 [29:11<02:04, 62.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30], Train Loss: 0.0151742286 , Val Loss: 0.0784072354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  97%|█████████▋| 29/30 [30:14<01:02, 62.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/30], Train Loss: 0.0149066471 , Val Loss: 0.0712109357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress: 100%|██████████| 30/30 [31:16<00:00, 62.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/30], Train Loss: 0.0146322355 , Val Loss: 0.0746502057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "criterion2 = DiceLoss()\n",
    "best_val_loss = 999\n",
    "epoch_bar = tqdm(total=num_epochs, desc='Total Progress')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        labels = labels.squeeze(dim=1).long()\n",
    "        outputs = model(images)\n",
    "    \n",
    "        loss1 = criterion1(outputs, labels)\n",
    "        loss2 = criterion2(outputs, labels)\n",
    "        loss = loss1 + loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.squeeze(dim=1).long()\n",
    "            \n",
    "            outputs = model(images)\n",
    "\n",
    "            val_loss1 = criterion1(outputs,labels)\n",
    "            val_loss2 = criterion2(outputs,labels)\n",
    "            val_loss += val_loss1 + val_loss2\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss/len(train_loader):.10f} , Val Loss: {val_loss/len(val_loader):.10f}\")\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        checkpoint = { \n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'loss': val_loss,\n",
    "        }\n",
    "        save_path = f'model.pth'\n",
    "        torch.save(checkpoint, save_path)\n",
    "        \n",
    "    epoch_bar.update(1)\n",
    "    wandb.log({'Val_loss': val_loss/len(val_loader),'Train_loss': train_loss/len(train_loader)})\n",
    "epoch_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T06:04:23.675077Z",
     "iopub.status.busy": "2024-11-23T06:04:23.674819Z",
     "iopub.status.idle": "2024-11-23T06:04:24.471436Z",
     "shell.execute_reply": "2024-11-23T06:04:24.470645Z",
     "shell.execute_reply.started": "2024-11-23T06:04:23.675052Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/4249454291.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('model.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): EfficientNetEncoder(\n",
       "    (_conv_stem): Conv2dStaticSamePadding(\n",
       "      3, 64, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "      (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "    )\n",
       "    (_bn0): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          64, 64, kernel_size=(3, 3), stride=[1, 1], groups=64, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          64, 16, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          16, 64, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (1-3): 3 x MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (4): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=[2, 2], groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (5-10): 6 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(3, 3), stride=(1, 1), groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (11): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(5, 5), stride=[2, 2], groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (12-17): 6 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(5, 5), stride=(1, 1), groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (18): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(3, 3), stride=[2, 2], groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (19-27): 9 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (28): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=[1, 1], groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 224, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (29-37): 9 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1344, 56, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          56, 1344, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (38): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1344, 1344, kernel_size=(5, 5), stride=[2, 2], groups=1344, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1344, 56, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          56, 1344, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (39-50): 12 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (51): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          2304, 2304, kernel_size=(3, 3), stride=[1, 1], groups=2304, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(640, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (52-54): 3 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(3840, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          3840, 3840, kernel_size=(3, 3), stride=(1, 1), groups=3840, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(3840, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          3840, 160, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          160, 3840, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(640, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "    )\n",
       "    (_conv_head): Conv2dStaticSamePadding(\n",
       "      640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (_bn1): BatchNorm2d(2560, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (_dropout): Dropout(p=0.5, inplace=False)\n",
       "    (_swish): MemoryEfficientSwish()\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(864, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(336, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(176, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('model.pth')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T06:04:24.472765Z",
     "iopub.status.busy": "2024-11-23T06:04:24.472487Z",
     "iopub.status.idle": "2024-11-23T06:04:25.545485Z",
     "shell.execute_reply": "2024-11-23T06:04:25.544265Z",
     "shell.execute_reply.started": "2024-11-23T06:04:24.472727Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!mkdir prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T06:04:25.548256Z",
     "iopub.status.busy": "2024-11-23T06:04:25.547910Z",
     "iopub.status.idle": "2024-11-23T06:04:49.965053Z",
     "shell.execute_reply": "2024-11-23T06:04:49.964055Z",
     "shell.execute_reply.started": "2024-11-23T06:04:25.548227Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for i in os.listdir(\"/kaggle/input/bkai-igh-neopolyp/test/test\"):\n",
    "    img_path = os.path.join(\"/kaggle/input/bkai-igh-neopolyp/test/test\", i)\n",
    "    ori_img = cv2.imread(img_path)\n",
    "    ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n",
    "    ori_w = ori_img.shape[0]\n",
    "    ori_h = ori_img.shape[1]\n",
    "    img = cv2.resize(ori_img, (256, 256))\n",
    "    transformed = val_transforms(image=img)\n",
    "    input_img = transformed[\"image\"]\n",
    "    input_img = input_img.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output_mask = model.forward(input_img).squeeze(0).cpu().numpy().transpose(1,2,0)\n",
    "    mask = cv2.resize(output_mask, (ori_h, ori_w))\n",
    "    mask = np.argmax(mask, axis=2)\n",
    "    mask_rgb = mask_to_rgb(mask, color_dict)\n",
    "    mask_rgb = cv2.cvtColor(mask_rgb, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(\"/kaggle/working/prediction/{}\".format(i), mask_rgb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T06:04:49.966557Z",
     "iopub.status.busy": "2024-11-23T06:04:49.966272Z",
     "iopub.status.idle": "2024-11-23T06:04:51.530822Z",
     "shell.execute_reply": "2024-11-23T06:04:51.529947Z",
     "shell.execute_reply.started": "2024-11-23T06:04:49.966530Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction/0626ab4ec3d46e602b296cc5cfd263f1.jpeg\n",
      "prediction/88e16d4ca6160127cd1d5ff99c267599.jpeg\n",
      "prediction/cc5cfd263f1f90be28799235026b3550.jpeg\n",
      "prediction/5a51625559c7e610b1531871f2fd85a0.jpeg\n",
      "prediction/77e004e8bfb905b78a91391adc0bb223.jpeg\n",
      "prediction/780fd497e1c0e9082ea2c193ac8d551c.jpeg\n",
      "prediction/6ddca6ee1af35b65bd9ea42cfcfedb5e.jpeg\n",
      "prediction/019410b1fcf0625f608b4ce97629ab55.jpeg\n",
      "prediction/30c2f4fc276ed9f178dc2f4af6266509.jpeg\n",
      "prediction/936de314f2d95e6c487ffa651b477422.jpeg\n",
      "prediction/05b78a91391adc0bb223c4eaf3372eae.jpeg\n",
      "prediction/f7fdb2d45b21960c94b0aab4c024a573.jpeg\n",
      "prediction/5c1346e62522325c1b9c4fc9cbe1eca1.jpeg\n",
      "prediction/a15fc656702fa602bb3c7abacdbd7e6a.jpeg\n",
      "prediction/f8e26031fbb5e52c41545ba55aadaa77.jpeg\n",
      "prediction/1ad4f13ccf1f4b331a412fc44655fb51.jpeg\n",
      "prediction/5beb48f0be11d0309d1dff09b8405734.jpeg\n",
      "prediction/c7e610b1531871f2fd85a04faeeb2b53.jpeg\n",
      "prediction/8eb5a9a8a8d7fcc9df8e5ad89d284483.jpeg\n",
      "prediction/6ad1468996b4a9ce6d840b53a6558038.jpeg\n",
      "prediction/8fa8625605da2023387fd56c04414eaa.jpeg\n",
      "prediction/7af2ed9fbb63b28163a745959c039830.jpeg\n",
      "prediction/8395e56a6d9ba9d45c3dbc695325ded4.jpeg\n",
      "prediction/9632a3c6f7f7fb2a643f15bd0249ddcc.jpeg\n",
      "prediction/15fc656702fa602bb3c7abacdbd7e6af.jpeg\n",
      "prediction/98da48d679d7c7c8d3d96fb2b87fbbcf.jpeg\n",
      "prediction/2a365b5574868eb60861ee1ff0b8a4f6.jpeg\n",
      "prediction/45b21960c94b0aab4c024a573c692195.jpeg\n",
      "prediction/63b8318ecf467d7ad048df39beb17636.jpeg\n",
      "prediction/2ed9fbb63b28163a745959c03983064a.jpeg\n",
      "prediction/a9d45c3dbc695325ded465efde988dfb.jpeg\n",
      "prediction/dc70626ab4ec3d46e602b296cc5cfd26.jpeg\n",
      "prediction/9c7976c1182df0de51d32128c358d1fd.jpeg\n",
      "prediction/c4be73749a0d21db70dd094a7f32574d.jpeg\n",
      "prediction/e2cd066b9fdbc3bbc04a3afe1f119f21.jpeg\n",
      "prediction/eff05dec1eb3a70b145a7d8d3b6c0ed7.jpeg\n",
      "prediction/a6a4248a41e8db8b4ed633b456aaafac.jpeg\n",
      "prediction/aeeb2b535797395305af926a6f23c5d6.jpeg\n",
      "prediction/df8e26031fbb5e52c41545ba55aadaa7.jpeg\n",
      "prediction/f8e5ad89d2844837f2a0f1536ad3f6a5.jpeg\n",
      "prediction/ad43fe2cd066b9fdbc3bbc04a3afe1f1.jpeg\n",
      "prediction/0af3feff05dec1eb3a70b145a7d8d3b6.jpeg\n",
      "prediction/fdbc3bbc04a3afe1f119f21b248d152b.jpeg\n",
      "prediction/fe1f119f21b248d152b672ab3492fc62.jpeg\n",
      "prediction/626650908b1cb932a767bf5487ced51b.jpeg\n",
      "prediction/3c84417fda8019410b1fcf0625f608b4.jpeg\n",
      "prediction/4f437f0019f7e6af7d7147763bdfb928.jpeg\n",
      "prediction/eb1ef57af2ed9fbb63b28163a745959c.jpeg\n",
      "prediction/be4d18d5401f659532897255ce2dd4ae.jpeg\n",
      "prediction/c41545ba55aadaa77712a48e11d579d9.jpeg\n",
      "prediction/7b5df7cdf3f33c3ca4d5060a633a8d5b.jpeg\n",
      "prediction/3c3ca4d5060a633a8d5b2b2b55157b77.jpeg\n",
      "prediction/3c692195f853af7f8a4df1ec859759b7.jpeg\n",
      "prediction/cf464aa36bf7c09a3bb0e5ca159410b9.jpeg\n",
      "prediction/6f67b5df7cdf3f33c3ca4d5060a633a8.jpeg\n",
      "prediction/fb905b78a91391adc0bb223c4eaf3372.jpeg\n",
      "prediction/80cae6daedd989517cb8041ed86e5822.jpeg\n",
      "prediction/4c1711b62f15ec83b97bb11e8e0c4416.jpeg\n",
      "prediction/7cb2eb1ef57af2ed9fbb63b28163a745.jpeg\n",
      "prediction/6240619ebebe9e9c9d00a4262b4fe4a5.jpeg\n",
      "prediction/559c7e610b1531871f2fd85a04faeeb2.jpeg\n",
      "prediction/72d9e593b6be1ac29adbe86f03d900fd.jpeg\n",
      "prediction/6f4d4987ea3b4bae5672a230194c5a08.jpeg\n",
      "prediction/cbb2a365b5574868eb60861ee1ff0b8a.jpeg\n",
      "prediction/a6e51d077bad31c8c5f54ffaa27a6235.jpeg\n",
      "prediction/998906d3694abb47953b0e4909384b57.jpeg\n",
      "prediction/391adc0bb223c4eaf3372eae567c94ea.jpeg\n",
      "prediction/ea42b4eebc9e5a87e443434ac60af150.jpeg\n",
      "prediction/d694539ef2424a9218697283baa3657e.jpeg\n",
      "prediction/ca4d5060a633a8d5b2b2b55157b7781e.jpeg\n",
      "prediction/05734fbeedd0f9da760db74a29abdb04.jpeg\n",
      "prediction/5664c1711b62f15ec83b97bb11e8e0c4.jpeg\n",
      "prediction/be86f03d900fd197cd955fa095f97845.jpeg\n",
      "prediction/87133b51209db6dcdda5cc8a788edaeb.jpeg\n",
      "prediction/66e057db382b8564872a27301a654864.jpeg\n",
      "prediction/94a7f32574d6c748c41743c6c08a1d1a.jpeg\n",
      "prediction/a6d9ba9d45c3dbc695325ded465efde9.jpeg\n",
      "prediction/7ad1cf2eb9d32a3dc907950289e976c7.jpeg\n",
      "prediction/4fda8daadc8dd23ae214d84b5dec33fd.jpeg\n",
      "prediction/1db239dda50f954ba59c7de13a35276a.jpeg\n",
      "prediction/425b976973f13dd311a65d2b46d0a608.jpeg\n",
      "prediction/af35b65bd9ea42cfcfedb5eb2a0e4b50.jpeg\n",
      "prediction/d5060a633a8d5b2b2b55157b7781e2c7.jpeg\n",
      "prediction/ff55177a34fc01019eec999fd84e679b.jpeg\n",
      "prediction/c5a0808bee60b246359c68c836f843dc.jpeg\n",
      "prediction/d3694abb47953b0e4909384b57bb6a05.jpeg\n",
      "prediction/c22268d4b4ef4d95ceea11957998906d.jpeg\n",
      "prediction/7936140a2d5fc1443c4e445927738677.jpeg\n",
      "prediction/aafac813fe3ccba3e032dd2948a80c64.jpeg\n",
      "prediction/8b8ec74baddc22268d4b4ef4d95ceea1.jpeg\n",
      "prediction/7fda8019410b1fcf0625f608b4ce9762.jpeg\n",
      "prediction/e73749a0d21db70dd094a7f32574d6c7.jpeg\n",
      "prediction/0a0317371a966bf4b3466463a3c64db1.jpeg\n",
      "prediction/7cdf3f33c3ca4d5060a633a8d5b2b2b5.jpeg\n",
      "prediction/7f32574d6c748c41743c6c08a1d1ad8f.jpeg\n",
      "prediction/c193ac8d551c149b60f2965341caf528.jpeg\n",
      "prediction/3bbc04a3afe1f119f21b248d152b672a.jpeg\n",
      "prediction/2cd066b9fdbc3bbc04a3afe1f119f21b.jpeg\n",
      "prediction/80c643782707d7c359e27888daefee82.jpeg\n",
      "prediction/6679bff55177a34fc01019eec999fd84.jpeg\n",
      "prediction/df366e057db382b8564872a27301a654.jpeg\n",
      "prediction/e4a17af18f72c8e6166a915669c99390.jpeg\n",
      "prediction/39dda50f954ba59c7de13a35276a4764.jpeg\n",
      "prediction/41ed86e58224cb76a67d4dcf9596154e.jpeg\n",
      "prediction/cdf3f33c3ca4d5060a633a8d5b2b2b55.jpeg\n",
      "prediction/dd78294679c9cbb2a365b5574868eb60.jpeg\n",
      "prediction/02fa602bb3c7abacdbd7e6afd56ea7bc.jpeg\n",
      "prediction/1b62f15ec83b97bb11e8e0c4416c1931.jpeg\n",
      "prediction/318ecf467d7ad048df39beb176363408.jpeg\n",
      "prediction/633a8d5b2b2b55157b7781e2c706c75c.jpeg\n",
      "prediction/5e8f14e1e0ae936de314f2d95e6c487f.jpeg\n",
      "prediction/c695325ded465efde988dfb96d081533.jpeg\n",
      "prediction/e5e8f14e1e0ae936de314f2d95e6c487.jpeg\n",
      "prediction/285e26c90e1797c77826f9a7021bab9f.jpeg\n",
      "prediction/4ca6160127cd1d5ff99c267599fc487b.jpeg\n",
      "prediction/7f0019f7e6af7d7147763bdfb928d788.jpeg\n",
      "prediction/dd094a7f32574d6c748c41743c6c08a1.jpeg\n",
      "prediction/dc0bb223c4eaf3372eae567c94ea04c6.jpeg\n",
      "prediction/97e1c0e9082ea2c193ac8d551c149b60.jpeg\n",
      "prediction/677a6b1f2c6d40b3bbba8f6c704801b3.jpeg\n",
      "prediction/26679bff55177a34fc01019eec999fd8.jpeg\n",
      "prediction/cb2eb1ef57af2ed9fbb63b28163a7459.jpeg\n",
      "prediction/d6bf62f215f0da4ad3a7ab8df9da7386.jpeg\n",
      "prediction/0fca6a4248a41e8db8b4ed633b456aaa.jpeg\n",
      "prediction/f14e1e0ae936de314f2d95e6c487ffa6.jpeg\n",
      "prediction/461c2a337948a41964c1d4f50a5f3601.jpeg\n",
      "prediction/82ea2c193ac8d551c149b60f2965341c.jpeg\n",
      "prediction/39d6aad6bb0170a40ed32deef71fbe08.jpeg\n",
      "prediction/e1797c77826f9a7021bab9fc73303988.jpeg\n",
      "prediction/3b8318ecf467d7ad048df39beb176363.jpeg\n",
      "prediction/3657e4314fe384eb2ba3adfda6c1899f.jpeg\n",
      "prediction/afe1f119f21b248d152b672ab3492fc6.jpeg\n",
      "prediction/3425b976973f13dd311a65d2b46d0a60.jpeg\n",
      "prediction/a51625559c7e610b1531871f2fd85a04.jpeg\n",
      "prediction/d077bad31c8c5f54ffaa27a623511c38.jpeg\n",
      "prediction/b70dd094a7f32574d6c748c41743c6c0.jpeg\n",
      "prediction/4417fda8019410b1fcf0625f608b4ce9.jpeg\n",
      "prediction/1002ec4a1fe748f3085f1ce88cbdf366.jpeg\n",
      "prediction/4e2a6e51d077bad31c8c5f54ffaa27a6.jpeg\n",
      "prediction/13dd311a65d2b46d0a6085835c525af6.jpeg\n",
      "prediction/ff05dec1eb3a70b145a7d8d3b6c0ed75.jpeg\n",
      "prediction/0a5f3601ad4f13ccf1f4b331a412fc44.jpeg\n",
      "prediction/692195f853af7f8a4df1ec859759b7c8.jpeg\n",
      "prediction/e8bfb905b78a91391adc0bb223c4eaf3.jpeg\n",
      "prediction/0619ebebe9e9c9d00a4262b4fe4a5a95.jpeg\n",
      "prediction/e56a6d9ba9d45c3dbc695325ded465ef.jpeg\n",
      "prediction/b21960c94b0aab4c024a573c692195f8.jpeg\n",
      "prediction/5026b3550534bca540e24f489284b8e6.jpeg\n",
      "prediction/e1e0ae936de314f2d95e6c487ffa651b.jpeg\n",
      "prediction/6b83ef461c2a337948a41964c1d4f50a.jpeg\n",
      "prediction/2d9e593b6be1ac29adbe86f03d900fd1.jpeg\n",
      "prediction/4ef4d95ceea11957998906d3694abb47.jpeg\n",
      "prediction/60b246359c68c836f843dcf41f4dce3c.jpeg\n",
      "prediction/4e8bfb905b78a91391adc0bb223c4eaf.jpeg\n",
      "prediction/cf6644589e532a9ee954f81faedbce39.jpeg\n",
      "prediction/71f2fd85a04faeeb2b535797395305af.jpeg\n",
      "prediction/8cbdf366e057db382b8564872a27301a.jpeg\n",
      "prediction/eecd70ebce6347c491b37c8c2e5a64a8.jpeg\n",
      "prediction/50534bca540e24f489284b8e6953ad88.jpeg\n",
      "prediction/1209db6dcdda5cc8a788edaeb6aa460a.jpeg\n",
      "prediction/0398846f67b5df7cdf3f33c3ca4d5060.jpeg\n",
      "prediction/54ba59c7de13a35276a476420655433a.jpeg\n",
      "prediction/6231002ec4a1fe748f3085f1ce88cbdf.jpeg\n",
      "prediction/faef7fdb2d45b21960c94b0aab4c024a.jpeg\n",
      "prediction/f13dd311a65d2b46d0a6085835c525af.jpeg\n",
      "prediction/bec33b5e3d68f9d4c331587f9b9d49e2.jpeg\n",
      "prediction/e9082ea2c193ac8d551c149b60f29653.jpeg\n",
      "prediction/85a04faeeb2b535797395305af926a6f.jpeg\n",
      "prediction/395e56a6d9ba9d45c3dbc695325ded46.jpeg\n",
      "prediction/c656702fa602bb3c7abacdbd7e6afd56.jpeg\n",
      "prediction/782707d7c359e27888daefee82519763.jpeg\n",
      "prediction/1c0e9082ea2c193ac8d551c149b60f29.jpeg\n",
      "prediction/5b21960c94b0aab4c024a573c692195f.jpeg\n",
      "prediction/a3657e4314fe384eb2ba3adfda6c1899.jpeg\n",
      "prediction/fcd6da15fc656702fa602bb3c7abacdb.jpeg\n",
      "prediction/e3c84417fda8019410b1fcf0625f608b.jpeg\n",
      "prediction/625559c7e610b1531871f2fd85a04fae.jpeg\n",
      "prediction/8954bb13d3727c7e5e1069646f2f0bb8.jpeg\n",
      "prediction/3dd311a65d2b46d0a6085835c525af63.jpeg\n",
      "prediction/710d568df17586ad8f3297c819c90895.jpeg\n",
      "prediction/3f33c3ca4d5060a633a8d5b2b2b55157.jpeg\n",
      "prediction/314fe384eb2ba3adfda6c1899fdc9837.jpeg\n",
      "prediction/e19769fa2d37d32780fd497e1c0e9082.jpeg\n",
      "prediction/67d4dcf9596154efb7cef748d9cbd617.jpeg\n",
      "prediction/68d4b4ef4d95ceea11957998906d3694.jpeg\n",
      "prediction/7330398846f67b5df7cdf3f33c3ca4d5.jpeg\n",
      "prediction/cb1b387133b51209db6dcdda5cc8a788.jpeg\n",
      "prediction/4baddc22268d4b4ef4d95ceea1195799.jpeg\n",
      "prediction/a48847ae8395e56a6d9ba9d45c3dbc69.jpeg\n",
      "prediction/f62f215f0da4ad3a7ab8df9da7386835.jpeg\n",
      "prediction/db5eb2a0e4b50889d874c68c030b9afe.jpeg\n",
      "prediction/9fc7330398846f67b5df7cdf3f33c3ca.jpeg\n",
      "prediction/d6240619ebebe9e9c9d00a4262b4fe4a.jpeg\n",
      "prediction/1531871f2fd85a04faeeb2b535797395.jpeg\n",
      "prediction/6d3694abb47953b0e4909384b57bb6a0.jpeg\n",
      "prediction/268d4b4ef4d95ceea11957998906d369.jpeg\n",
      "prediction/60a633a8d5b2b2b55157b7781e2c706c.jpeg\n",
      "prediction/e7998934d417cb2eb1ef57af2ed9fbb6.jpeg\n",
      "prediction/27738677a6b1f2c6d40b3bbba8f6c704.jpeg\n",
      "prediction/343f27ebc5d92b9076135d76d0bbd4ce.jpeg\n"
     ]
    }
   ],
   "source": [
    "def rle_to_string(runs):\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_encode_one_mask(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels[pixels > 225] = 255\n",
    "    pixels[pixels <= 225] = 0\n",
    "    use_padding = False\n",
    "    if pixels[0] or pixels[-1]:\n",
    "        use_padding = True\n",
    "        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n",
    "        pixel_padded[1:-1] = pixels\n",
    "        pixels = pixel_padded\n",
    "    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    if use_padding:\n",
    "        rle = rle - 1\n",
    "    rle[1::2] = rle[1::2] - rle[:-1:2]\n",
    "    \n",
    "    return rle_to_string(rle)\n",
    "\n",
    "def rle2mask(mask_rle, shape=(3,3)):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def mask2string(dir):\n",
    "    strings = []\n",
    "    ids = []\n",
    "    ws, hs = [[] for i in range(2)]\n",
    "    for image_id in os.listdir(dir):\n",
    "        id = image_id.split('.')[0]\n",
    "        path = os.path.join(dir, image_id)\n",
    "        print(path)\n",
    "        img = cv2.imread(path)[:,:,::-1]\n",
    "        h, w = img.shape[0], img.shape[1]\n",
    "        for channel in range(2):\n",
    "            ws.append(w)\n",
    "            hs.append(h)\n",
    "            ids.append(f'{id}_{channel}')\n",
    "            string = rle_encode_one_mask(img[:,:,channel])\n",
    "            strings.append(string)\n",
    "    r = {\n",
    "        'ids': ids,\n",
    "        'strings': strings,\n",
    "    }\n",
    "    return r\n",
    "\n",
    "\n",
    "MASK_DIR_PATH = 'prediction/'\n",
    "dir = MASK_DIR_PATH\n",
    "res = mask2string(dir)\n",
    "df = pd.DataFrame(columns=['Id', 'Expected'])\n",
    "df['Id'] = res['ids']\n",
    "df['Expected'] = res['strings']\n",
    "\n",
    "df.to_csv(r'output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 2715462,
     "sourceId": 30892,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
